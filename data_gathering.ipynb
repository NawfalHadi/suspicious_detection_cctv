{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a811b75",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20d5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affba089",
   "metadata": {},
   "source": [
    "# Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d0883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "100919a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_pose(cam, label, output='pose_keypoints.csv'):\n",
    "    cap = cv2.VideoCapture(cam)\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Recolor Feed\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            \n",
    "            # Make Detections\n",
    "            results = holistic.process(image)\n",
    "            # print(results.face_landmarks)\n",
    "            \n",
    "            # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "            \n",
    "            # Recolor image back to BGR for rendering\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                    )\n",
    "            \n",
    "            try:\n",
    "                pose = results.pose_landmarks.landmark\n",
    "                pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "                pose_row.insert(0, label)\n",
    "                \n",
    "                with open(output, mode='a', newline='') as f:\n",
    "                    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    writer.writerow(pose_row)\n",
    "            except:\n",
    "                pass\n",
    "                            \n",
    "            cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726b485d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 34):\n",
    "    landmarks += [f'x{val}', f'y{val}', f'z{val}', f'v{val}']\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d84ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pose_keypoints.csv', mode='w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c79c7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_pose(0, 'suspicious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e397f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresult\u001b[49m.pose_landmarks\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result.pose_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb63c3d",
   "metadata": {},
   "source": [
    "# YOLO V11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c760c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-pose.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a7a18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_pose_yolo(cam, label, output='yolo_keypoints.csv'):\n",
    "    cap = cv2.VideoCapture(cam)\n",
    "    # Initiate holistic model\n",
    "        \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = model(image)\n",
    "\n",
    "\n",
    "        for result in results:\n",
    "            image = result.plot()\n",
    "\n",
    "            kp_array = result.keypoints.xy.cpu().numpy()[0]\n",
    "            flat_keypoints = kp_array.flatten().tolist()\n",
    "            row = [label] + flat_keypoints\n",
    "\n",
    "            # Save to CSV\n",
    "            with open(output, mode='a', newline='') as f:\n",
    "                writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                writer.writerow(row)\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca7858c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'x17',\n",
       " 'y17']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = 17\n",
    "\n",
    "landmarks = ['class']\n",
    "for val in range(1, num_coords + 1):\n",
    "    landmarks += [f'x{val}', f'y{val}']\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13cea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yolo_keypoints.csv', mode='w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e4f4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 833.8ms\n",
      "Speed: 58.8ms preprocess, 833.8ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 463.9ms\n",
      "Speed: 4.2ms preprocess, 463.9ms inference, 18.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 462.5ms\n",
      "Speed: 3.4ms preprocess, 462.5ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 422.5ms\n",
      "Speed: 5.5ms preprocess, 422.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 417.7ms\n",
      "Speed: 3.5ms preprocess, 417.7ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 429.8ms\n",
      "Speed: 3.6ms preprocess, 429.8ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 425.1ms\n",
      "Speed: 3.5ms preprocess, 425.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 376.6ms\n",
      "Speed: 3.6ms preprocess, 376.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 390.2ms\n",
      "Speed: 3.3ms preprocess, 390.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2014.7ms\n",
      "Speed: 5.5ms preprocess, 2014.7ms inference, 22.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2304.9ms\n",
      "Speed: 23.0ms preprocess, 2304.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 427.1ms\n",
      "Speed: 4.1ms preprocess, 427.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 444.9ms\n",
      "Speed: 3.6ms preprocess, 444.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 540.7ms\n",
      "Speed: 4.5ms preprocess, 540.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 485.2ms\n",
      "Speed: 4.1ms preprocess, 485.2ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 421.1ms\n",
      "Speed: 4.5ms preprocess, 421.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 497.3ms\n",
      "Speed: 4.7ms preprocess, 497.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 412.9ms\n",
      "Speed: 3.7ms preprocess, 412.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 441.2ms\n",
      "Speed: 3.3ms preprocess, 441.2ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 487.2ms\n",
      "Speed: 3.8ms preprocess, 487.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 469.3ms\n",
      "Speed: 3.7ms preprocess, 469.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 512.7ms\n",
      "Speed: 3.4ms preprocess, 512.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 436.7ms\n",
      "Speed: 3.8ms preprocess, 436.7ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2620.6ms\n",
      "Speed: 4.1ms preprocess, 2620.6ms inference, 31.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 464.2ms\n",
      "Speed: 4.4ms preprocess, 464.2ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 491.2ms\n",
      "Speed: 4.6ms preprocess, 491.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 428.2ms\n",
      "Speed: 3.6ms preprocess, 428.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 397.4ms\n",
      "Speed: 3.8ms preprocess, 397.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3987.8ms\n",
      "Speed: 23.9ms preprocess, 3987.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 435.8ms\n",
      "Speed: 3.4ms preprocess, 435.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 430.0ms\n",
      "Speed: 3.4ms preprocess, 430.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 414.7ms\n",
      "Speed: 3.6ms preprocess, 414.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 437.9ms\n",
      "Speed: 3.4ms preprocess, 437.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 502.1ms\n",
      "Speed: 4.1ms preprocess, 502.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 445.6ms\n",
      "Speed: 3.8ms preprocess, 445.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 419.7ms\n",
      "Speed: 3.5ms preprocess, 419.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 452.0ms\n",
      "Speed: 4.1ms preprocess, 452.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 432.7ms\n",
      "Speed: 4.3ms preprocess, 432.7ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 458.1ms\n",
      "Speed: 3.8ms preprocess, 458.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 387.0ms\n",
      "Speed: 4.2ms preprocess, 387.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 400.0ms\n",
      "Speed: 6.3ms preprocess, 400.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3141.2ms\n",
      "Speed: 3.9ms preprocess, 3141.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "capture_pose_yolo(0, 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0138ba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 412.2ms\n",
      "Speed: 3.3ms preprocess, 412.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 462.2ms\n",
      "Speed: 4.1ms preprocess, 462.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 483.5ms\n",
      "Speed: 3.9ms preprocess, 483.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 471.6ms\n",
      "Speed: 4.5ms preprocess, 471.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 562.7ms\n",
      "Speed: 3.5ms preprocess, 562.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 434.6ms\n",
      "Speed: 2.7ms preprocess, 434.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 485.8ms\n",
      "Speed: 3.7ms preprocess, 485.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 477.0ms\n",
      "Speed: 3.3ms preprocess, 477.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 488.6ms\n",
      "Speed: 3.9ms preprocess, 488.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 460.8ms\n",
      "Speed: 3.8ms preprocess, 460.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 468.6ms\n",
      "Speed: 4.1ms preprocess, 468.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 432.9ms\n",
      "Speed: 4.3ms preprocess, 432.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 478.2ms\n",
      "Speed: 3.5ms preprocess, 478.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2549.3ms\n",
      "Speed: 4.6ms preprocess, 2549.3ms inference, 18.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 874.1ms\n",
      "Speed: 29.0ms preprocess, 874.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 512.4ms\n",
      "Speed: 3.6ms preprocess, 512.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 370.4ms\n",
      "Speed: 3.4ms preprocess, 370.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 385.7ms\n",
      "Speed: 2.7ms preprocess, 385.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 469.1ms\n",
      "Speed: 4.2ms preprocess, 469.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 449.7ms\n",
      "Speed: 3.6ms preprocess, 449.7ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 433.3ms\n",
      "Speed: 3.8ms preprocess, 433.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 443.5ms\n",
      "Speed: 3.6ms preprocess, 443.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 458.6ms\n",
      "Speed: 4.0ms preprocess, 458.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 444.4ms\n",
      "Speed: 3.7ms preprocess, 444.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 376.4ms\n",
      "Speed: 3.8ms preprocess, 376.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 422.2ms\n",
      "Speed: 3.6ms preprocess, 422.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1040.8ms\n",
      "Speed: 3.4ms preprocess, 1040.8ms inference, 54.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2259.5ms\n",
      "Speed: 26.7ms preprocess, 2259.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 793.5ms\n",
      "Speed: 4.4ms preprocess, 793.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 382.4ms\n",
      "Speed: 3.5ms preprocess, 382.4ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 387.6ms\n",
      "Speed: 4.2ms preprocess, 387.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 377.8ms\n",
      "Speed: 3.3ms preprocess, 377.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 419.5ms\n",
      "Speed: 3.7ms preprocess, 419.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3916.6ms\n",
      "Speed: 3.8ms preprocess, 3916.6ms inference, 27.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 467.8ms\n",
      "Speed: 4.8ms preprocess, 467.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 410.6ms\n",
      "Speed: 3.6ms preprocess, 410.6ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 4289.1ms\n",
      "Speed: 3.4ms preprocess, 4289.1ms inference, 33.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 939.6ms\n",
      "Speed: 21.0ms preprocess, 939.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 666.7ms\n",
      "Speed: 3.8ms preprocess, 666.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 418.8ms\n",
      "Speed: 3.4ms preprocess, 418.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 511.9ms\n",
      "Speed: 3.4ms preprocess, 511.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 481.1ms\n",
      "Speed: 3.9ms preprocess, 481.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 493.8ms\n",
      "Speed: 3.8ms preprocess, 493.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "capture_pose_yolo(0, 'suspicious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ab726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
