{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9c43a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/users/nawfal/documents/apps/collaborative project/cctv_motion_detection/motion_venv/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3691d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7267d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tcp @ 0x1d2fab40] Connection to tcp://10.223.206.104:5000 failed: Connection timed out\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the camera\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m camera = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttp://10.223.206.104:5000/video\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Check if the camera opened successfully\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m camera.isOpened():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize the camera\n",
    "camera = cv2.VideoCapture(\"http://10.223.206.104:5000/video\")\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2b290bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "Saved 30 frames.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_frames = int(input(\"How many frames do you want? \"))\n",
    "frames = []\n",
    "\n",
    "camera = cv2.VideoCapture(\"http://10.223.206.104:5000/video\")\n",
    "\n",
    "desire_fps = 10\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Save the frame to the test/frames folder\n",
    "        # Ensure the directory exists before saving\n",
    "        os.makedirs(\"test/frames\", exist_ok=True)\n",
    "        filename = f\"test/frames/frame_{len(frames)}.jpg\"\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "        frames.append(frame)\n",
    "        print(len(frames))\n",
    "\n",
    "        if len(frames) >= num_frames:\n",
    "            print(f\"Saved {num_frames} frames.\")\n",
    "            break\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)\n",
    "\n",
    "    # Delay to simulate target FPS\n",
    "    elapsed = time.time() - start_time\n",
    "    sleep_time = max(0, frame_delay - elapsed)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ec453",
   "metadata": {},
   "source": [
    "# Get Continously Frame\n",
    "the output is the list always changed while camera running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd66ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_frames = int(input(\"How many frames do you want? \"))\n",
    "frames = []\n",
    "\n",
    "camera = cv2.VideoCapture(\"http://10.223.206.104:5000/video\")\n",
    "\n",
    "desire_fps = 10\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Save the frame to the test/frames folder\n",
    "        # Ensure the directory exists before saving\n",
    "\n",
    "\n",
    "        # cek apakah list nya ada None\n",
    "        if len(frames) < num_frames:\n",
    "            frames.append(frame)\n",
    "            print(\"append\")\n",
    "        else:\n",
    "            # do a movement where the list work move from second index to the fist index\n",
    "            # third index to the second index and so on\n",
    "            # the first index will be deleted\n",
    "            # the last index will be added from the camera\n",
    "            frames.pop(0)\n",
    "            print(\"pop\")\n",
    "\n",
    "        print(len(frames))\n",
    "\n",
    "        if len(frames) >= num_frames:\n",
    "            print(f\"Saved {num_frames} frames.\")\n",
    "            break\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)\n",
    "\n",
    "    # Delay to simulate target FPS\n",
    "    elapsed = time.time() - start_time\n",
    "    sleep_time = max(0, frame_delay - elapsed)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25109664",
   "metadata": {},
   "source": [
    "# Show Testing GUI\n",
    "i want the output is to show all of FRAMEn while camera active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3559351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(\"http://10.223.240.174:5000/video\")\n",
    "num_frames = 15\n",
    "\n",
    "original_width, original_height = 500, 500\n",
    "small_width, small_height = 150, 150\n",
    "\n",
    "default_frame = 255 * np.ones((small_height, small_width, 3), dtype=np.uint8)\n",
    "\n",
    "desire_fps = 10\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "frames = []\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, (original_width, original_height))\n",
    "\n",
    "        if len(frames) < num_frames:\n",
    "            frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "        else:\n",
    "            frames.pop(0)\n",
    "            frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "        \n",
    "        print(len(frames))\n",
    "\n",
    "        # 3 rows vertically stacked\n",
    "\n",
    "        if len(frames) >= 15:\n",
    "            stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "            stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "            stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "            stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "            stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "            # Resize to match width of original frame\n",
    "            stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "            stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "            stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "            stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "            stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "\n",
    "            final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "        else:\n",
    "            final_layout = frame  # or show default layout\n",
    "\n",
    "        \n",
    "        # Delay to simulate target FPS\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, frame_delay - elapsed)\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Camera Capture\", final_layout)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56193f8a",
   "metadata": {},
   "source": [
    "# Implement Landmark On Running Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c593e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3e54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "\n",
    "\" Offset value should be based on the size of player detection \"\n",
    "offset = 10 # temp value\n",
    "\n",
    "line_thickness = 2\n",
    "line_color = (0, 255, 0)  # Green color\n",
    "line_color_red = (0, 0, 255)  # Red color\n",
    "line_color_blue = (255, 0, 0)  # Blue color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3b284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desire_fps = 15\n",
    "num_frames = 15\n",
    "\n",
    "original_width, original_height = 500, 500\n",
    "small_width, small_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca14e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748061829.277569     741 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1748061829.300517    6944 gl_context.cc:369] GL version: 3.1 (OpenGL ES 3.1 Mesa 24.0.9-0ubuntu0.3), renderer: D3D12 (AMD Radeon(TM) Graphics)\n",
      "W0000 00:00:1748061829.958679    6933 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748061830.634472    6934 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748061830.685195    6932 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748061830.686826    6942 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748061830.693451    6935 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748061830.702073    6934 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748061830.716585    6940 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748061830.723706    6941 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "9\n",
      "4\n",
      "12\n",
      "5\n",
      "15\n",
      "6\n",
      "18\n",
      "7\n",
      "21\n",
      "8\n",
      "24\n",
      "9\n",
      "27\n",
      "10\n",
      "30\n",
      "11\n",
      "33\n",
      "12\n",
      "36\n",
      "13\n",
      "39\n",
      "14\n",
      "42\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n",
      "15\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(\"http://192.168.1.26:5000/video\")\n",
    "\n",
    "frames = []\n",
    "detected = []\n",
    "\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    while camera.isOpened:\n",
    "        start_time = time.time()\n",
    "        ret, frame = camera.read()\n",
    "        \n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (original_width, original_height))\n",
    "\n",
    "\n",
    "            if len(frames) < num_frames:\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "                \n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                temporary_list = []\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EYE])\n",
    "                \n",
    "                detected.append(temporary_list)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                frames.pop(0)\n",
    "                detected.pop(0)\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "\n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                temporary_list = []\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EYE])\n",
    "                \n",
    "                detected.append(temporary_list)\n",
    "\n",
    "            print(len(detected))\n",
    "\n",
    "            if len(frames) >= 15:\n",
    "                stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "                stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "                stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "                stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "                stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "                stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "                stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "                stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "                stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "                stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "                \n",
    "                final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "            else:\n",
    "                final_layout = frame\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Flatten the list of lists in detected to a single list\n",
    "            flat_detected = [landmark for sublist in detected for landmark in sublist]\n",
    "            print(len(flat_detected))\n",
    "\n",
    "            landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "            landmark_list.landmark.extend(flat_detected)\n",
    "\n",
    "            cv2.imshow(\"Camera Capture\", final_layout)\n",
    "            if cv2.waitKey (1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae06f435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33',\n",
       " 'x34',\n",
       " 'y34',\n",
       " 'z34',\n",
       " 'v34',\n",
       " 'x35',\n",
       " 'y35',\n",
       " 'z35',\n",
       " 'v35',\n",
       " 'x36',\n",
       " 'y36',\n",
       " 'z36',\n",
       " 'v36',\n",
       " 'x37',\n",
       " 'y37',\n",
       " 'z37',\n",
       " 'v37',\n",
       " 'x38',\n",
       " 'y38',\n",
       " 'z38',\n",
       " 'v38',\n",
       " 'x39',\n",
       " 'y39',\n",
       " 'z39',\n",
       " 'v39',\n",
       " 'x40',\n",
       " 'y40',\n",
       " 'z40',\n",
       " 'v40',\n",
       " 'x41',\n",
       " 'y41',\n",
       " 'z41',\n",
       " 'v41',\n",
       " 'x42',\n",
       " 'y42',\n",
       " 'z42',\n",
       " 'v42',\n",
       " 'x43',\n",
       " 'y43',\n",
       " 'z43',\n",
       " 'v43',\n",
       " 'x44',\n",
       " 'y44',\n",
       " 'z44',\n",
       " 'v44',\n",
       " 'x45',\n",
       " 'y45',\n",
       " 'z45',\n",
       " 'v45']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_coords = len(landmark_list.landmark)\n",
    "used_coords\n",
    "\n",
    "landmarks = ['class']\n",
    "for val in range(1, used_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ae9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv = 'dataset/csv/finale_coords.csv'\n",
    "os.makedirs(os.path.dirname(file_csv), exist_ok=True)\n",
    "\n",
    "with open(file_csv, mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e35f19",
   "metadata": {},
   "source": [
    "# Capture Dataset With Camera (Experimental)\n",
    "the output is to creating and collecting dataset that will be trained\n",
    "\n",
    "\n",
    "planning :\n",
    "- create a countdown, while the user do something\n",
    "- after a countdown stop, capture the last 15 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16137bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b009e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748062051.342971     741 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1748062051.366171    8018 gl_context.cc:369] GL version: 3.1 (OpenGL ES 3.1 Mesa 24.0.9-0ubuntu0.3), renderer: D3D12 (AMD Radeon(TM) Graphics)\n",
      "W0000 00:00:1748062051.629600    8007 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748062051.784714    8009 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748062051.796467    8006 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748062051.797243    8015 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748062051.808317    8009 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748062051.814333    8006 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748062051.816892    8007 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1748062051.818385    8008 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 0 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 1 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 2 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n",
      "Elapsed time: 3 seconds\n"
     ]
    }
   ],
   "source": [
    "class_name = \"Celinguk\"\n",
    "camera = cv2.VideoCapture(\"http://192.168.1.26:5000/video\")\n",
    "\n",
    "frames = []\n",
    "detected = []\n",
    "\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while camera.isOpened:\n",
    "        countdown_time = 3\n",
    "        \n",
    "        ret, frame = camera.read()\n",
    "        \n",
    "        if ret:\n",
    "\n",
    "            frame = cv2.resize(frame, (original_width, original_height))\n",
    "            if len(frames) < num_frames:\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "                \n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                temporary_list = []\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EYE])\n",
    "                \n",
    "                detected.append(temporary_list)\n",
    "                \n",
    "            else:\n",
    "                frames.pop(0)\n",
    "                detected.pop(0)\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "\n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                temporary_list = []\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EYE])\n",
    "                \n",
    "                detected.append(temporary_list)\n",
    "\n",
    "            if len(frames) >= 15:\n",
    "                stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "                stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "                stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "                stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "                stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "                stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "                stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "                stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "                stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "                stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "                \n",
    "                final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "            else:\n",
    "                final_layout = frame\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            flat_detected = [landmark for sublist in detected for landmark in sublist]\n",
    "\n",
    "            landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "            landmark_list.landmark.extend(flat_detected)\n",
    "            \n",
    "\n",
    "            cv2.imshow(\"Camera Capture\", final_layout)\n",
    "            \n",
    "\n",
    "            # Print the elapsed time in seconds since the start of the loop\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            if elapsed <= 3:\n",
    "                print(f\"Elapsed time: {elapsed} seconds\")\n",
    "                  \n",
    "            else:\n",
    "                lv = landmark_list.landmark\n",
    "                dataset_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in lv]).flatten()) \n",
    "                \n",
    "                dataset_row.insert(0, class_name)\n",
    "\n",
    "                with open(file_csv, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(dataset_row)\n",
    "                break\n",
    "            \n",
    "\n",
    "            if cv2.waitKey (1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb20e62",
   "metadata": {},
   "source": [
    "# - All above creating a based of how to create the input -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633929fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/users/nawfal/documents/apps/collaborative project/cctv_motion_detection/pose_env/bin/python'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440347b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motion_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
