{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9c43a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/users/nawfal/documents/apps/collaborative project/cctv_motion_detection/motion_venv/bin/python'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df3691d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebb4d3",
   "metadata": {},
   "source": [
    "# Camera Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7267d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the camera\n",
    "camera = cv2.VideoCapture(\"http://192.168.100.197:5000/video\")\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b290bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m num_frames = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow many frames do you want? \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m frames = []\n\u001b[32m      6\u001b[39m camera = cv2.VideoCapture(\u001b[33m\"\u001b[39m\u001b[33mhttp://192.168.50.234:5000/video\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_frames = int(input(\"How many frames do you want? \"))\n",
    "frames = []\n",
    "\n",
    "camera = cv2.VideoCapture(\"http://192.168.50.234:5000/video\")\n",
    "\n",
    "desire_fps = 10\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Save the frame to the test/frames folder\n",
    "        # Ensure the directory exists before saving\n",
    "        os.makedirs(\"test/frames\", exist_ok=True)\n",
    "        filename = f\"test/frames/frame_{len(frames)}.jpg\"\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "        frames.append(frame)\n",
    "        print(len(frames))\n",
    "\n",
    "        if len(frames) >= num_frames:\n",
    "            print(f\"Saved {num_frames} frames.\")\n",
    "            break\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)q\n",
    "\n",
    "    # Delay to simulate target FPS\n",
    "    elapsed = time.time() - start_time\n",
    "    sleep_time = max(0, frame_delay - elapsed)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ec453",
   "metadata": {},
   "source": [
    "# Get Continously Frame\n",
    "the output is the list always changed while camera running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd66ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n",
      "append\n",
      "1\n",
      "append\n",
      "2\n",
      "append\n",
      "3\n",
      "append\n",
      "4\n",
      "append\n",
      "5\n",
      "append\n",
      "6\n",
      "append\n",
      "7\n",
      "append\n",
      "8\n",
      "append\n",
      "9\n",
      "append\n",
      "10\n",
      "append\n",
      "11\n",
      "append\n",
      "12\n",
      "append\n",
      "13\n",
      "append\n",
      "14\n",
      "append\n",
      "15\n",
      "Saved 15 frames.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_frames = int(input(\"How many frames do you want? \"))\n",
    "frames = []\n",
    "\n",
    "camera = cv2.VideoCapture(\"http://192.168.50.234:5000/video\")\n",
    "\n",
    "desire_fps = 10\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Save the frame to the test/frames folder\n",
    "        # Ensure the directory exists before saving\n",
    "\n",
    "\n",
    "        # cek apakah list nya ada None\n",
    "        if len(frames) < num_frames:\n",
    "            frames.append(frame)\n",
    "            print(\"append\")\n",
    "        else:\n",
    "            # do a movement where the list work move from second index to the fist index\n",
    "            # third index to the second index and so on\n",
    "            # the first index will be deleted\n",
    "            # the last index will be added from the camera\n",
    "            frames.pop(0)\n",
    "            print(\"pop\")\n",
    "\n",
    "        print(len(frames))\n",
    "\n",
    "        if len(frames) >= num_frames:\n",
    "            print(f\"Saved {num_frames} frames.\")\n",
    "            break\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)\n",
    "\n",
    "    # Delay to simulate target FPS\n",
    "    elapsed = time.time() - start_time\n",
    "    sleep_time = max(0, frame_delay - elapsed)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25109664",
   "metadata": {},
   "source": [
    "# Show Testing GUI\n",
    "i want the output is to show all of FRAMEn while camera active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3559351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(\"http://192.168.100.197:5000/video\")\n",
    "num_frames = 15\n",
    "\n",
    "original_width, original_height = 500, 500\n",
    "small_width, small_height = 150, 150\n",
    "\n",
    "default_frame = 255 * np.ones((small_height, small_width, 3), dtype=np.uint8)\n",
    "\n",
    "desire_fps = 20\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "frames = []\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, (original_width, original_height))\n",
    "\n",
    "        if len(frames) < num_frames:\n",
    "            frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "        else:\n",
    "            frames.pop(0)\n",
    "            frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "        \n",
    "        print(len(frames))\n",
    "\n",
    "        # 3 rows vertically stacked\n",
    "\n",
    "        if len(frames) >= 15:\n",
    "            stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "            stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "            stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "            stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "            stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "            # Resize to match width of original frame\n",
    "            stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "            stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "            stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "            stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "            stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "\n",
    "            final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "        else:\n",
    "            final_layout = frame  # or show default layout\n",
    "\n",
    "        \n",
    "        # Delay to simulate target FPS\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, frame_delay - elapsed)\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Camera Capture\", final_layout)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56193f8a",
   "metadata": {},
   "source": [
    "# Implement Landmark On Running Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c593e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd3e54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "\n",
    "\" Offset value should be based on the size of player detection \"\n",
    "offset = 10 # temp value\n",
    "\n",
    "line_thickness = 2\n",
    "line_color = (0, 255, 0)  # Green color\n",
    "line_color_red = (0, 0, 255)  # Red color\n",
    "line_color_blue = (255, 0, 0)  # Blue color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f3b284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desire_fps = 15\n",
    "num_frames = 15\n",
    "\n",
    "original_width, original_height = 500, 500\n",
    "small_width, small_height = 150, 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e474a9",
   "metadata": {},
   "source": [
    "# Get Landmark of frames By Initialized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca14e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MESA: error: ZINK: failed to choose pdev\n",
      "libEGL warning: egl: failed to create dri2 screen\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756214187.480419   16070 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1756214187.532882   17804 gl_context.cc:369] GL version: 3.1 (OpenGL ES 3.1 Mesa 24.0.9-0ubuntu0.3), renderer: D3D12 (AMD Radeon(TM) Graphics)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1756214188.050914   17783 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214188.327717   17786 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214188.349401   17790 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1756214188.351580   17787 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214188.354677   17789 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214188.369426   17792 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214188.395001   17783 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214188.407352   17785 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214188.408923   17788 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(\"http://192.168.50.19:5000/video\")\n",
    "\n",
    "frames = []\n",
    "detected = []\n",
    "\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while camera.isOpened:\n",
    "        start_time = time.time()\n",
    "        ret, frame = camera.read()\n",
    "        \n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (original_width, original_height))\n",
    "\n",
    "\n",
    "            if len(frames) < num_frames:\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "                \n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                temporary_list = []\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_WRIST])\n",
    "                \n",
    "                detected.append(temporary_list)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                frames.pop(0)\n",
    "                detected.pop(0)\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "\n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                temporary_list = []\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_WRIST])\n",
    "\n",
    "                detected.append(temporary_list)\n",
    "\n",
    "            if len(frames) >= 15:\n",
    "                stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "                stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "                stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "                stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "                stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "                stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "                stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "                stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "                stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "                stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "                \n",
    "                final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "            else:\n",
    "                final_layout = frame\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Flatten the list of lists in detected to a single list\n",
    "            flat_detected = [landmark for sublist in detected for landmark in sublist]\n",
    "            print(len(flat_detected))\n",
    "\n",
    "            landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "            landmark_list.landmark.extend(flat_detected)\n",
    "\n",
    "            cv2.imshow(\"Camera Capture\", final_layout)\n",
    "            if cv2.waitKey (1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae06f435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'face_d1',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'face_d2',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'face_d3',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'face_d4',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'face_d5',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'face_d6',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33',\n",
       " 'x34',\n",
       " 'y34',\n",
       " 'z34',\n",
       " 'v34',\n",
       " 'x35',\n",
       " 'y35',\n",
       " 'z35',\n",
       " 'v35',\n",
       " 'face_d7',\n",
       " 'x36',\n",
       " 'y36',\n",
       " 'z36',\n",
       " 'v36',\n",
       " 'x37',\n",
       " 'y37',\n",
       " 'z37',\n",
       " 'v37',\n",
       " 'x38',\n",
       " 'y38',\n",
       " 'z38',\n",
       " 'v38',\n",
       " 'x39',\n",
       " 'y39',\n",
       " 'z39',\n",
       " 'v39',\n",
       " 'x40',\n",
       " 'y40',\n",
       " 'z40',\n",
       " 'v40',\n",
       " 'face_d8',\n",
       " 'x41',\n",
       " 'y41',\n",
       " 'z41',\n",
       " 'v41',\n",
       " 'x42',\n",
       " 'y42',\n",
       " 'z42',\n",
       " 'v42',\n",
       " 'x43',\n",
       " 'y43',\n",
       " 'z43',\n",
       " 'v43',\n",
       " 'x44',\n",
       " 'y44',\n",
       " 'z44',\n",
       " 'v44',\n",
       " 'x45',\n",
       " 'y45',\n",
       " 'z45',\n",
       " 'v45',\n",
       " 'face_d9',\n",
       " 'x46',\n",
       " 'y46',\n",
       " 'z46',\n",
       " 'v46',\n",
       " 'x47',\n",
       " 'y47',\n",
       " 'z47',\n",
       " 'v47',\n",
       " 'x48',\n",
       " 'y48',\n",
       " 'z48',\n",
       " 'v48',\n",
       " 'x49',\n",
       " 'y49',\n",
       " 'z49',\n",
       " 'v49',\n",
       " 'x50',\n",
       " 'y50',\n",
       " 'z50',\n",
       " 'v50',\n",
       " 'face_d10',\n",
       " 'x51',\n",
       " 'y51',\n",
       " 'z51',\n",
       " 'v51',\n",
       " 'x52',\n",
       " 'y52',\n",
       " 'z52',\n",
       " 'v52',\n",
       " 'x53',\n",
       " 'y53',\n",
       " 'z53',\n",
       " 'v53',\n",
       " 'x54',\n",
       " 'y54',\n",
       " 'z54',\n",
       " 'v54',\n",
       " 'x55',\n",
       " 'y55',\n",
       " 'z55',\n",
       " 'v55',\n",
       " 'face_d11',\n",
       " 'x56',\n",
       " 'y56',\n",
       " 'z56',\n",
       " 'v56',\n",
       " 'x57',\n",
       " 'y57',\n",
       " 'z57',\n",
       " 'v57',\n",
       " 'x58',\n",
       " 'y58',\n",
       " 'z58',\n",
       " 'v58',\n",
       " 'x59',\n",
       " 'y59',\n",
       " 'z59',\n",
       " 'v59',\n",
       " 'x60',\n",
       " 'y60',\n",
       " 'z60',\n",
       " 'v60',\n",
       " 'face_d12',\n",
       " 'x61',\n",
       " 'y61',\n",
       " 'z61',\n",
       " 'v61',\n",
       " 'x62',\n",
       " 'y62',\n",
       " 'z62',\n",
       " 'v62',\n",
       " 'x63',\n",
       " 'y63',\n",
       " 'z63',\n",
       " 'v63',\n",
       " 'x64',\n",
       " 'y64',\n",
       " 'z64',\n",
       " 'v64',\n",
       " 'x65',\n",
       " 'y65',\n",
       " 'z65',\n",
       " 'v65',\n",
       " 'face_d13',\n",
       " 'x66',\n",
       " 'y66',\n",
       " 'z66',\n",
       " 'v66',\n",
       " 'x67',\n",
       " 'y67',\n",
       " 'z67',\n",
       " 'v67',\n",
       " 'x68',\n",
       " 'y68',\n",
       " 'z68',\n",
       " 'v68',\n",
       " 'x69',\n",
       " 'y69',\n",
       " 'z69',\n",
       " 'v69',\n",
       " 'x70',\n",
       " 'y70',\n",
       " 'z70',\n",
       " 'v70',\n",
       " 'face_d14',\n",
       " 'x71',\n",
       " 'y71',\n",
       " 'z71',\n",
       " 'v71',\n",
       " 'x72',\n",
       " 'y72',\n",
       " 'z72',\n",
       " 'v72',\n",
       " 'x73',\n",
       " 'y73',\n",
       " 'z73',\n",
       " 'v73',\n",
       " 'x74',\n",
       " 'y74',\n",
       " 'z74',\n",
       " 'v74',\n",
       " 'x75',\n",
       " 'y75',\n",
       " 'z75',\n",
       " 'v75',\n",
       " 'face_d15']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_coords = len(landmark_list.landmark)\n",
    "used_coords\n",
    "frames = 1\n",
    "\n",
    "landmarks = ['class']\n",
    "for val in range(1, used_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "    if val % 5 == 0:\n",
    "        landmarks += ['face_d{}'.format(frames)]\n",
    "        frames += 1\n",
    "\n",
    "\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ae9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv = 'dataset/csv/ds_face_direction.csv'\n",
    "os.makedirs(os.path.dirname(file_csv), exist_ok=True)\n",
    "\n",
    "with open(file_csv, mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e35f19",
   "metadata": {},
   "source": [
    "# Capture Dataset With Camera (Experimental)\n",
    "the output is to creating and collecting dataset that will be trained\n",
    "\n",
    "\n",
    "planning :\n",
    "- create a countdown, while the user do something\n",
    "- after a countdown stop, capture the last 15 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16137bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_direction(landmark):\n",
    "    direction = \"Right\"\n",
    "    smallest_value = min(landmark, key=landmark.get)\n",
    "    highest_value = max(landmark, key=landmark.get)\n",
    "    \n",
    "    if smallest_value == \"nose\":\n",
    "        direction = 0\n",
    "    elif highest_value == \"nose\":\n",
    "        direction = 1\n",
    "    else:\n",
    "        direction = 2\n",
    "    \n",
    "    return direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b009e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756214562.996079   16070 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1756214563.022549   19084 gl_context.cc:369] GL version: 3.1 (OpenGL ES 3.1 Mesa 24.0.9-0ubuntu0.3), renderer: D3D12 (AMD Radeon(TM) Graphics)\n",
      "W0000 00:00:1756214563.300409   19073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214563.497291   19072 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214563.511660   19076 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214563.516518   19074 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214563.526335   19080 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214563.526497   19073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214563.544271   19079 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756214563.556748   19073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.5510237216949463 seconds\n",
      "Elapsed time: 0.6648380756378174 seconds\n",
      "Elapsed time: 0.7684171199798584 seconds\n",
      "Elapsed time: 0.8719005584716797 seconds\n",
      "Elapsed time: 0.975292444229126 seconds\n",
      "Elapsed time: 1.0787889957427979 seconds\n",
      "Elapsed time: 1.1823453903198242 seconds\n",
      "Elapsed time: 1.2858154773712158 seconds\n",
      "Elapsed time: 1.3890869617462158 seconds\n",
      "Elapsed time: 1.4926931858062744 seconds\n",
      "Elapsed time: 1.5961740016937256 seconds\n",
      "Elapsed time: 1.6998891830444336 seconds\n",
      "Elapsed time: 1.803614616394043 seconds\n",
      "Elapsed time: 1.9074516296386719 seconds\n",
      "Elapsed time: 2.0110321044921875 seconds\n",
      "Elapsed time: 2.1344263553619385 seconds\n",
      "Elapsed time: 2.237863540649414 seconds\n",
      "Elapsed time: 2.342531681060791 seconds\n",
      "Elapsed time: 2.4460129737854004 seconds\n",
      "Elapsed time: 2.550131320953369 seconds\n",
      "Elapsed time: 2.6543776988983154 seconds\n",
      "Elapsed time: 2.7587521076202393 seconds\n",
      "Elapsed time: 2.8626229763031006 seconds\n",
      "Elapsed time: 2.966552734375 seconds\n",
      "Elapsed time: 3.0705981254577637 seconds\n",
      "Elapsed time: 3.1748735904693604 seconds\n",
      "Elapsed time: 3.2792775630950928 seconds\n",
      "Elapsed time: 3.383274793624878 seconds\n",
      "Elapsed time: 3.4871654510498047 seconds\n",
      "Elapsed time: 3.5917580127716064 seconds\n",
      "Elapsed time: 3.695341110229492 seconds\n",
      "Elapsed time: 3.799499273300171 seconds\n",
      "Elapsed time: 3.903599500656128 seconds\n",
      "Elapsed time: 4.00747275352478 seconds\n",
      "Elapsed time: 4.1115124225616455 seconds\n",
      "Elapsed time: 4.215946197509766 seconds\n",
      "Elapsed time: 4.320059776306152 seconds\n",
      "Elapsed time: 4.424529314041138 seconds\n",
      "Elapsed time: 4.528043031692505 seconds\n",
      "Elapsed time: 4.632497310638428 seconds\n",
      "Elapsed time: 4.736143112182617 seconds\n",
      "Elapsed time: 4.840550422668457 seconds\n",
      "Elapsed time: 4.944252252578735 seconds\n",
      "Elapsed time: 5.048105239868164 seconds\n",
      "Elapsed time: 5.152036666870117 seconds\n",
      "Elapsed time: 5.256180763244629 seconds\n",
      "Elapsed time: 5.360729455947876 seconds\n",
      "Elapsed time: 5.4652979373931885 seconds\n",
      "Elapsed time: 5.569118976593018 seconds\n",
      "Elapsed time: 5.67437219619751 seconds\n",
      "Elapsed time: 5.778169631958008 seconds\n",
      "Elapsed time: 5.882669687271118 seconds\n",
      "Elapsed time: 5.986936807632446 seconds\n",
      "Elapsed time: 6.090984344482422 seconds\n",
      "Elapsed time: 6.195265293121338 seconds\n",
      "Elapsed time: 6.299594402313232 seconds\n",
      "Elapsed time: 6.404174089431763 seconds\n",
      "Elapsed time: 6.508607864379883 seconds\n",
      "Elapsed time: 6.6124773025512695 seconds\n",
      "Elapsed time: 6.716414451599121 seconds\n",
      "Elapsed time: 6.820617198944092 seconds\n",
      "Elapsed time: 6.924862623214722 seconds\n",
      "Elapsed time: 7.028508186340332 seconds\n",
      "Elapsed time: 7.13221549987793 seconds\n",
      "Elapsed time: 7.235931396484375 seconds\n",
      "Elapsed time: 7.340225696563721 seconds\n",
      "Elapsed time: 7.443917274475098 seconds\n",
      "Elapsed time: 7.5476367473602295 seconds\n",
      "Elapsed time: 7.65125584602356 seconds\n",
      "Elapsed time: 7.755525350570679 seconds\n",
      "Elapsed time: 7.8591694831848145 seconds\n",
      "Elapsed time: 7.963654279708862 seconds\n",
      "Elapsed time: 8.067148208618164 seconds\n",
      "Elapsed time: 8.171393394470215 seconds\n",
      "Elapsed time: 8.274657249450684 seconds\n",
      "Elapsed time: 8.378885984420776 seconds\n",
      "Elapsed time: 8.482259035110474 seconds\n",
      "Elapsed time: 8.586836576461792 seconds\n",
      "Elapsed time: 8.690663814544678 seconds\n",
      "Elapsed time: 8.79499888420105 seconds\n",
      "Elapsed time: 8.898985862731934 seconds\n",
      "Elapsed time: 9.00359296798706 seconds\n",
      "Elapsed time: 9.10811161994934 seconds\n",
      "Elapsed time: 9.212672710418701 seconds\n",
      "Elapsed time: 9.316375732421875 seconds\n",
      "Elapsed time: 9.420610189437866 seconds\n",
      "Elapsed time: 9.525412559509277 seconds\n",
      "Elapsed time: 9.629819393157959 seconds\n",
      "Elapsed time: 9.733702182769775 seconds\n",
      "Elapsed time: 9.838332653045654 seconds\n",
      "Elapsed time: 9.942655801773071 seconds\n"
     ]
    }
   ],
   "source": [
    "class_name = \"CelingakCelinguk\"\n",
    "camera = cv2.VideoCapture(\"http://192.168.50.19:5000/video\")\n",
    "\n",
    "frames = []\n",
    "detected = []\n",
    "face_direction = []\n",
    "\n",
    "desire_fps = 10\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while camera.isOpened:\n",
    "        delay_frame_time = time.time()\n",
    "        countdown_time = 10\n",
    "        \n",
    "        ret, frame = camera.read()\n",
    "        \n",
    "        if ret:\n",
    "\n",
    "            frame = cv2.resize(frame, (original_width, original_height))\n",
    "\n",
    "            if len(frames) < num_frames:\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "                \n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                nose = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE]\n",
    "                ear_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EAR]\n",
    "                ear_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EAR]\n",
    "                wrist_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "                wrist_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "                temporary_list = []\n",
    "                temporary_list.append(nose)\n",
    "                temporary_list.append(ear_l)\n",
    "                temporary_list.append(ear_r)\n",
    "                temporary_list.append(wrist_r)\n",
    "                temporary_list.append(wrist_l)\n",
    "                \n",
    "                face_direction.append(check_direction({\"nose\": nose.x, \"ear_r\": ear_r.x, \"ear_l\": ear_l.x}))\n",
    "                detected.append(temporary_list)\n",
    "                \n",
    "            else:\n",
    "                frames.pop(0)\n",
    "                face_direction.pop(0)\n",
    "                detected.pop(0)\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "\n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                nose = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE]\n",
    "                ear_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EAR]\n",
    "                ear_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EAR]\n",
    "                wrist_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "                wrist_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "                \n",
    "                temporary_list = []\n",
    "                temporary_list.append(nose)\n",
    "                temporary_list.append(ear_l)\n",
    "                temporary_list.append(ear_r)\n",
    "                temporary_list.append(wrist_r)\n",
    "                temporary_list.append(wrist_l)\n",
    "                \n",
    "                face_direction.append(check_direction({\"nose\": nose.x, \"ear_r\": ear_r.x, \"ear_l\": ear_l.x}))\n",
    "                detected.append(temporary_list)\n",
    "\n",
    "            if len(frames) >= 15:\n",
    "                stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "                stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "                stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "                stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "                stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "                stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "                stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "                stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "                stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "                stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "                \n",
    "                final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "            else:\n",
    "                final_layout = frame\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            flat_detected = [landmark for sublist in detected for landmark in sublist]\n",
    "\n",
    "            landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "            landmark_list.landmark.extend(flat_detected)\n",
    "            \n",
    "            cv2.imshow(\"Camera Capture\", final_layout)\n",
    "\n",
    "            # Print the elapsed time in seconds since the start of the loop\n",
    "            \n",
    "            fps = time.time() - delay_frame_time\n",
    "            sleep_time = max(0, frame_delay - fps)\n",
    "            \n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            if elapsed <= 10:\n",
    "                print(f\"Elapsed time: {elapsed} seconds\")\n",
    "                    \n",
    "            else:\n",
    "                lv = landmark_list.landmark\n",
    "\n",
    "                counter = 0\n",
    "                featureper_frames = 0\n",
    "                dataset_row = []\n",
    "                \n",
    "                for lndmrk in lv:\n",
    "                    dataset_row.append(lndmrk.x)\n",
    "                    dataset_row.append(lndmrk.y)\n",
    "                    dataset_row.append(lndmrk.z)\n",
    "                    dataset_row.append(lndmrk.visibility)\n",
    "                    counter += 1\n",
    "\n",
    "                    if counter % 5 == 0:\n",
    "                        dataset_row.append(face_direction[featureper_frames])\n",
    "                        featureper_frames += 1 \n",
    "\n",
    "                dataset_row = list(np.array(dataset_row))\n",
    "                dataset_row.insert(0, class_name)\n",
    "\n",
    "                with open(file_csv, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(dataset_row)\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey (1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a0cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cb20e62",
   "metadata": {},
   "source": [
    "# - NOTE -\n",
    "1. West, East detection where we see as additional of parameter when detecting suspicious activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633929fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/users/nawfal/documents/apps/collaborative project/cctv_motion_detection/pose_env/bin/python'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc473f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440347b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motion_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
