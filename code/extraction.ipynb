{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9c43a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/users/nawfal/documents/apps/collaborative project/cctv_motion_detection/motion_venv/bin/python'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3691d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebb4d3",
   "metadata": {},
   "source": [
    "# Camera Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7267d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the camera\n",
    "camera = cv2.VideoCapture(\"http://192.168.100.197:5000/video\")\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b290bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m num_frames = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow many frames do you want? \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m frames = []\n\u001b[32m      6\u001b[39m camera = cv2.VideoCapture(\u001b[33m\"\u001b[39m\u001b[33mhttp://192.168.50.234:5000/video\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_frames = int(input(\"How many frames do you want? \"))\n",
    "frames = []\n",
    "\n",
    "camera = cv2.VideoCapture(\"http://192.168.50.234:5000/video\")\n",
    "\n",
    "desire_fps = 10\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Save the frame to the test/frames folder\n",
    "        # Ensure the directory exists before saving\n",
    "        os.makedirs(\"test/frames\", exist_ok=True)\n",
    "        filename = f\"test/frames/frame_{len(frames)}.jpg\"\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "        frames.append(frame)\n",
    "        print(len(frames))\n",
    "\n",
    "        if len(frames) >= num_frames:\n",
    "            print(f\"Saved {num_frames} frames.\")\n",
    "            break\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)q\n",
    "\n",
    "    # Delay to simulate target FPS\n",
    "    elapsed = time.time() - start_time\n",
    "    sleep_time = max(0, frame_delay - elapsed)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ec453",
   "metadata": {},
   "source": [
    "# Get Continously Frame\n",
    "the output is the list always changed while camera running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd66ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n",
      "append\n",
      "1\n",
      "append\n",
      "2\n",
      "append\n",
      "3\n",
      "append\n",
      "4\n",
      "append\n",
      "5\n",
      "append\n",
      "6\n",
      "append\n",
      "7\n",
      "append\n",
      "8\n",
      "append\n",
      "9\n",
      "append\n",
      "10\n",
      "append\n",
      "11\n",
      "append\n",
      "12\n",
      "append\n",
      "13\n",
      "append\n",
      "14\n",
      "append\n",
      "15\n",
      "Saved 15 frames.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_frames = int(input(\"How many frames do you want? \"))\n",
    "frames = []\n",
    "\n",
    "camera = cv2.VideoCapture(\"http://192.168.50.234:5000/video\")\n",
    "\n",
    "desire_fps = 10\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "# Capture frames from the camera\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Save the frame to the test/frames folder\n",
    "        # Ensure the directory exists before saving\n",
    "\n",
    "\n",
    "        # cek apakah list nya ada None\n",
    "        if len(frames) < num_frames:\n",
    "            frames.append(frame)\n",
    "            print(\"append\")\n",
    "        else:\n",
    "            # do a movement where the list work move from second index to the fist index\n",
    "            # third index to the second index and so on\n",
    "            # the first index will be deleted\n",
    "            # the last index will be added from the camera\n",
    "            frames.pop(0)\n",
    "            print(\"pop\")\n",
    "\n",
    "        print(len(frames))\n",
    "\n",
    "        if len(frames) >= num_frames:\n",
    "            print(f\"Saved {num_frames} frames.\")\n",
    "            break\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.namedWindow(\"Camera Capture\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "    cv2.resizeWindow(\"Camera Capture\", 640, 480)\n",
    "    cv2.imshow(\"Camera Capture\", frame)\n",
    "\n",
    "    # Delay to simulate target FPS\n",
    "    elapsed = time.time() - start_time\n",
    "    sleep_time = max(0, frame_delay - elapsed)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25109664",
   "metadata": {},
   "source": [
    "# Show Testing GUI\n",
    "i want the output is to show all of FRAMEn while camera active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3559351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(\"http://192.168.100.197:5000/video\")\n",
    "num_frames = 15\n",
    "\n",
    "original_width, original_height = 500, 500\n",
    "small_width, small_height = 150, 150\n",
    "\n",
    "default_frame = 255 * np.ones((small_height, small_width, 3), dtype=np.uint8)\n",
    "\n",
    "desire_fps = 20\n",
    "frame_delay = 1.0 / desire_fps\n",
    "\n",
    "frames = []\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, (original_width, original_height))\n",
    "\n",
    "        if len(frames) < num_frames:\n",
    "            frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "        else:\n",
    "            frames.pop(0)\n",
    "            frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "        \n",
    "        print(len(frames))\n",
    "\n",
    "        # 3 rows vertically stacked\n",
    "\n",
    "        if len(frames) >= 15:\n",
    "            stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "            stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "            stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "            stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "            stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "            # Resize to match width of original frame\n",
    "            stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "            stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "            stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "            stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "            stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "\n",
    "            final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "        else:\n",
    "            final_layout = frame  # or show default layout\n",
    "\n",
    "        \n",
    "        # Delay to simulate target FPS\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, frame_delay - elapsed)\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Camera Capture\", final_layout)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56193f8a",
   "metadata": {},
   "source": [
    "# Implement Landmark On Running Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c593e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 17:02:04.039497: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756198924.064382     824 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756198924.070281     824 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756198924.094832     824 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756198924.094894     824 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756198924.094897     824 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756198924.094899     824 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-26 17:02:04.101368: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd3e54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "\n",
    "\" Offset value should be based on the size of player detection \"\n",
    "offset = 10 # temp value\n",
    "\n",
    "line_thickness = 2\n",
    "line_color = (0, 255, 0)  # Green color\n",
    "line_color_red = (0, 0, 255)  # Red color\n",
    "line_color_blue = (255, 0, 0)  # Blue color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f3b284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desire_fps = 15\n",
    "num_frames = 15\n",
    "\n",
    "original_width, original_height = 500, 500\n",
    "small_width, small_height = 150, 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e474a9",
   "metadata": {},
   "source": [
    "# Get Landmark of frames By Initialized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fca14e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756200299.485757     824 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1756200299.534805   10124 gl_context.cc:369] GL version: 3.1 (OpenGL ES 3.1 Mesa 24.0.9-0ubuntu0.3), renderer: D3D12 (AMD Radeon(TM) Graphics)\n",
      "W0000 00:00:1756200299.855031   10114 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756200300.044766   10117 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756200300.058846   10115 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756200300.060895   10120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756200300.079806   10117 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756200300.103248   10115 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756200300.108279   10114 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756200300.112709   10116 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(\"http://192.168.100.197:5000/video\")\n",
    "\n",
    "frames = []\n",
    "detected = []\n",
    "\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while camera.isOpened:\n",
    "        start_time = time.time()\n",
    "        ret, frame = camera.read()\n",
    "        \n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (original_width, original_height))\n",
    "\n",
    "\n",
    "            if len(frames) < num_frames:\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "                \n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                temporary_list = []\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_WRIST])\n",
    "                \n",
    "                detected.append(temporary_list)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                frames.pop(0)\n",
    "                detected.pop(0)\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "\n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                temporary_list = []\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EYE])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST])\n",
    "                temporary_list.append(results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_WRIST])\n",
    "\n",
    "                detected.append(temporary_list)\n",
    "\n",
    "            if len(frames) >= 15:\n",
    "                stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "                stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "                stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "                stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "                stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "                stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "                stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "                stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "                stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "                stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "                \n",
    "                final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "            else:\n",
    "                final_layout = frame\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Flatten the list of lists in detected to a single list\n",
    "            flat_detected = [landmark for sublist in detected for landmark in sublist]\n",
    "            print(len(flat_detected))\n",
    "\n",
    "            landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "            landmark_list.landmark.extend(flat_detected)\n",
    "\n",
    "            cv2.imshow(\"Camera Capture\", final_layout)\n",
    "            if cv2.waitKey (1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae06f435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'face_d1',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'face_d2',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'face_d3',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'face_d4',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'face_d5',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'face_d6',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33',\n",
       " 'x34',\n",
       " 'y34',\n",
       " 'z34',\n",
       " 'v34',\n",
       " 'x35',\n",
       " 'y35',\n",
       " 'z35',\n",
       " 'v35',\n",
       " 'face_d7',\n",
       " 'x36',\n",
       " 'y36',\n",
       " 'z36',\n",
       " 'v36',\n",
       " 'x37',\n",
       " 'y37',\n",
       " 'z37',\n",
       " 'v37',\n",
       " 'x38',\n",
       " 'y38',\n",
       " 'z38',\n",
       " 'v38',\n",
       " 'x39',\n",
       " 'y39',\n",
       " 'z39',\n",
       " 'v39',\n",
       " 'x40',\n",
       " 'y40',\n",
       " 'z40',\n",
       " 'v40',\n",
       " 'face_d8',\n",
       " 'x41',\n",
       " 'y41',\n",
       " 'z41',\n",
       " 'v41',\n",
       " 'x42',\n",
       " 'y42',\n",
       " 'z42',\n",
       " 'v42',\n",
       " 'x43',\n",
       " 'y43',\n",
       " 'z43',\n",
       " 'v43',\n",
       " 'x44',\n",
       " 'y44',\n",
       " 'z44',\n",
       " 'v44',\n",
       " 'x45',\n",
       " 'y45',\n",
       " 'z45',\n",
       " 'v45',\n",
       " 'face_d9',\n",
       " 'x46',\n",
       " 'y46',\n",
       " 'z46',\n",
       " 'v46',\n",
       " 'x47',\n",
       " 'y47',\n",
       " 'z47',\n",
       " 'v47',\n",
       " 'x48',\n",
       " 'y48',\n",
       " 'z48',\n",
       " 'v48',\n",
       " 'x49',\n",
       " 'y49',\n",
       " 'z49',\n",
       " 'v49',\n",
       " 'x50',\n",
       " 'y50',\n",
       " 'z50',\n",
       " 'v50',\n",
       " 'face_d10',\n",
       " 'x51',\n",
       " 'y51',\n",
       " 'z51',\n",
       " 'v51',\n",
       " 'x52',\n",
       " 'y52',\n",
       " 'z52',\n",
       " 'v52',\n",
       " 'x53',\n",
       " 'y53',\n",
       " 'z53',\n",
       " 'v53',\n",
       " 'x54',\n",
       " 'y54',\n",
       " 'z54',\n",
       " 'v54',\n",
       " 'x55',\n",
       " 'y55',\n",
       " 'z55',\n",
       " 'v55',\n",
       " 'face_d11',\n",
       " 'x56',\n",
       " 'y56',\n",
       " 'z56',\n",
       " 'v56',\n",
       " 'x57',\n",
       " 'y57',\n",
       " 'z57',\n",
       " 'v57',\n",
       " 'x58',\n",
       " 'y58',\n",
       " 'z58',\n",
       " 'v58',\n",
       " 'x59',\n",
       " 'y59',\n",
       " 'z59',\n",
       " 'v59',\n",
       " 'x60',\n",
       " 'y60',\n",
       " 'z60',\n",
       " 'v60',\n",
       " 'face_d12',\n",
       " 'x61',\n",
       " 'y61',\n",
       " 'z61',\n",
       " 'v61',\n",
       " 'x62',\n",
       " 'y62',\n",
       " 'z62',\n",
       " 'v62',\n",
       " 'x63',\n",
       " 'y63',\n",
       " 'z63',\n",
       " 'v63',\n",
       " 'x64',\n",
       " 'y64',\n",
       " 'z64',\n",
       " 'v64',\n",
       " 'x65',\n",
       " 'y65',\n",
       " 'z65',\n",
       " 'v65',\n",
       " 'face_d13',\n",
       " 'x66',\n",
       " 'y66',\n",
       " 'z66',\n",
       " 'v66',\n",
       " 'x67',\n",
       " 'y67',\n",
       " 'z67',\n",
       " 'v67',\n",
       " 'x68',\n",
       " 'y68',\n",
       " 'z68',\n",
       " 'v68',\n",
       " 'x69',\n",
       " 'y69',\n",
       " 'z69',\n",
       " 'v69',\n",
       " 'x70',\n",
       " 'y70',\n",
       " 'z70',\n",
       " 'v70',\n",
       " 'face_d14',\n",
       " 'x71',\n",
       " 'y71',\n",
       " 'z71',\n",
       " 'v71',\n",
       " 'x72',\n",
       " 'y72',\n",
       " 'z72',\n",
       " 'v72',\n",
       " 'x73',\n",
       " 'y73',\n",
       " 'z73',\n",
       " 'v73',\n",
       " 'x74',\n",
       " 'y74',\n",
       " 'z74',\n",
       " 'v74',\n",
       " 'x75',\n",
       " 'y75',\n",
       " 'z75',\n",
       " 'v75',\n",
       " 'face_d15']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_coords = len(landmark_list.landmark)\n",
    "used_coords\n",
    "frames = 1\n",
    "\n",
    "landmarks = ['class']\n",
    "for val in range(1, used_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "    if val % 5 == 0:\n",
    "        landmarks += ['face_d{}'.format(frames)]\n",
    "        frames += 1\n",
    "\n",
    "\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54ae9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv = 'dataset/csv/ds_face_direction.csv'\n",
    "os.makedirs(os.path.dirname(file_csv), exist_ok=True)\n",
    "\n",
    "with open(file_csv, mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e35f19",
   "metadata": {},
   "source": [
    "# Capture Dataset With Camera (Experimental)\n",
    "the output is to creating and collecting dataset that will be trained\n",
    "\n",
    "\n",
    "planning :\n",
    "- create a countdown, while the user do something\n",
    "- after a countdown stop, capture the last 15 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16137bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_direction(landmark):\n",
    "    direction = \"Right\"\n",
    "    smallest_value = min(landmark, key=landmark.get)\n",
    "    highest_value = max(landmark, key=landmark.get)\n",
    "    \n",
    "    if smallest_value == \"nose\":\n",
    "        direction = 0\n",
    "    elif highest_value == \"nose\":\n",
    "        direction = 1\n",
    "    else:\n",
    "        direction = 2\n",
    "    \n",
    "    return direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is ready. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756199665.440671     824 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1756199665.464238    7976 gl_context.cc:369] GL version: 3.1 (OpenGL ES 3.1 Mesa 24.0.9-0ubuntu0.3), renderer: D3D12 (AMD Radeon(TM) Graphics)\n",
      "W0000 00:00:1756199665.774500    7963 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756199665.943676    7964 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756199665.956715    7967 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756199665.962582    7970 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756199665.963431    7971 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756199665.982389    7974 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756199665.993120    7973 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1756199666.003210    7963 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.5594844818115234 seconds\n",
      "Elapsed time: 0.6218111515045166 seconds\n",
      "Elapsed time: 0.6587309837341309 seconds\n",
      "Elapsed time: 0.693030595779419 seconds\n",
      "Elapsed time: 0.7267889976501465 seconds\n",
      "Elapsed time: 0.7635610103607178 seconds\n",
      "Elapsed time: 0.8009884357452393 seconds\n",
      "Elapsed time: 0.8335154056549072 seconds\n",
      "Elapsed time: 0.8673927783966064 seconds\n",
      "Elapsed time: 0.8979291915893555 seconds\n",
      "Elapsed time: 0.9288430213928223 seconds\n",
      "Elapsed time: 0.9620838165283203 seconds\n",
      "Elapsed time: 0.995793342590332 seconds\n",
      "Elapsed time: 1.029425859451294 seconds\n",
      "Elapsed time: 1.0643818378448486 seconds\n",
      "Elapsed time: 1.129774808883667 seconds\n",
      "Elapsed time: 1.1669995784759521 seconds\n",
      "Elapsed time: 1.2005274295806885 seconds\n",
      "Elapsed time: 1.2396173477172852 seconds\n",
      "Elapsed time: 1.2727210521697998 seconds\n",
      "Elapsed time: 1.3053946495056152 seconds\n",
      "Elapsed time: 1.3393676280975342 seconds\n",
      "Elapsed time: 1.369699478149414 seconds\n",
      "Elapsed time: 1.4044411182403564 seconds\n",
      "Elapsed time: 1.4410972595214844 seconds\n",
      "Elapsed time: 1.4762847423553467 seconds\n",
      "Elapsed time: 1.5075504779815674 seconds\n",
      "Elapsed time: 1.5403690338134766 seconds\n",
      "Elapsed time: 1.5733246803283691 seconds\n",
      "Elapsed time: 1.6075894832611084 seconds\n",
      "Elapsed time: 1.6421051025390625 seconds\n",
      "Elapsed time: 1.6783816814422607 seconds\n",
      "Elapsed time: 1.714843988418579 seconds\n",
      "Elapsed time: 1.7499799728393555 seconds\n",
      "Elapsed time: 1.7846932411193848 seconds\n",
      "Elapsed time: 1.820289134979248 seconds\n",
      "Elapsed time: 1.860579013824463 seconds\n",
      "Elapsed time: 1.896935224533081 seconds\n",
      "Elapsed time: 1.931687355041504 seconds\n",
      "Elapsed time: 1.9702036380767822 seconds\n",
      "Elapsed time: 2.009699583053589 seconds\n",
      "Elapsed time: 2.049555540084839 seconds\n",
      "Elapsed time: 2.0891506671905518 seconds\n",
      "Elapsed time: 2.129070520401001 seconds\n",
      "Elapsed time: 2.1678929328918457 seconds\n",
      "Elapsed time: 2.2042856216430664 seconds\n",
      "Elapsed time: 2.241206407546997 seconds\n",
      "Elapsed time: 2.2781078815460205 seconds\n",
      "Elapsed time: 2.3174281120300293 seconds\n",
      "Elapsed time: 2.354067087173462 seconds\n",
      "Elapsed time: 2.39497971534729 seconds\n",
      "Elapsed time: 2.4290499687194824 seconds\n",
      "Elapsed time: 2.4647090435028076 seconds\n",
      "Elapsed time: 2.5057034492492676 seconds\n",
      "Elapsed time: 2.540745973587036 seconds\n",
      "Elapsed time: 2.5750038623809814 seconds\n",
      "Elapsed time: 2.614821434020996 seconds\n",
      "Elapsed time: 2.648383617401123 seconds\n",
      "Elapsed time: 2.6839449405670166 seconds\n",
      "Elapsed time: 2.7185769081115723 seconds\n",
      "Elapsed time: 2.755258321762085 seconds\n",
      "Elapsed time: 2.7917988300323486 seconds\n",
      "Elapsed time: 2.82955265045166 seconds\n",
      "Elapsed time: 2.8625712394714355 seconds\n",
      "Elapsed time: 2.8942413330078125 seconds\n",
      "Elapsed time: 2.9298343658447266 seconds\n",
      "Elapsed time: 2.966414451599121 seconds\n",
      "Elapsed time: 2.9996590614318848 seconds\n",
      "['CelingakCelinguk', np.float64(0.44558802247047424), np.float64(0.5943941473960876), np.float64(-1.3625056743621826), np.float64(0.9997528195381165), np.float64(0.6204668283462524), np.float64(0.5513256192207336), np.float64(-0.8525188565254211), np.float64(0.999422550201416), np.float64(0.3970579504966736), np.float64(0.527994692325592), np.float64(-0.6238659024238586), np.float64(0.9996700286865234), np.float64(0.068607397377491), np.float64(1.63180410861969), np.float64(-0.9622710347175598), np.float64(0.07189812511205673), np.float64(0.068607397377491), np.float64(1.63180410861969), np.float64(-0.9622710347175598), np.float64(0.07189812511205673), np.float64(0.4495088756084442), np.float64(0.5922175645828247), np.float64(-1.4497954845428467), np.float64(0.9997446537017822), np.float64(0.6206910014152527), np.float64(0.5507504940032959), np.float64(-0.8936821818351746), np.float64(0.9994061589241028), np.float64(0.39706093072891235), np.float64(0.5277398824691772), np.float64(-0.6895046830177307), np.float64(0.9996567368507385), np.float64(0.0684334933757782), np.float64(1.6368310451507568), np.float64(-0.9589474201202393), np.float64(0.0723189115524292), np.float64(0.0684334933757782), np.float64(1.6368310451507568), np.float64(-0.9589474201202393), np.float64(0.0723189115524292), np.float64(0.4503261148929596), np.float64(0.5919103026390076), np.float64(-1.5027689933776855), np.float64(0.999751091003418), np.float64(0.6207340359687805), np.float64(0.5506685972213745), np.float64(-0.9461879134178162), np.float64(0.999427080154419), np.float64(0.3952900767326355), np.float64(0.5277812480926514), np.float64(-0.7395349740982056), np.float64(0.9996628761291504), np.float64(0.06956999003887177), np.float64(1.6366504430770874), np.float64(-1.0036765336990356), np.float64(0.0723133310675621), np.float64(0.06956999003887177), np.float64(1.6366504430770874), np.float64(-1.0036765336990356), np.float64(0.0723133310675621), np.float64(0.45069727301597595), np.float64(0.5921029448509216), np.float64(-1.4999351501464844), np.float64(0.9997592568397522), np.float64(0.6208616495132446), np.float64(0.5511434078216553), np.float64(-0.935272753238678), np.float64(0.9994392991065979), np.float64(0.3941968083381653), np.float64(0.5284116268157959), np.float64(-0.7473188638687134), np.float64(0.9996733665466309), np.float64(0.07099533826112747), np.float64(1.6374444961547852), np.float64(-1.0602577924728394), np.float64(0.07609140872955322), np.float64(0.07099533826112747), np.float64(1.6374444961547852), np.float64(-1.0602577924728394), np.float64(0.07609140872955322), np.float64(0.4579112231731415), np.float64(0.5921151638031006), np.float64(-1.5397844314575195), np.float64(0.9997603893280029), np.float64(0.6218987703323364), np.float64(0.5511550307273865), np.float64(-0.9566599130630493), np.float64(0.9994379878044128), np.float64(0.3938030004501343), np.float64(0.5286458730697632), np.float64(-0.803979754447937), np.float64(0.9996750354766846), np.float64(0.07076719403266907), np.float64(1.638075590133667), np.float64(-1.186326026916504), np.float64(0.07782134413719177), np.float64(0.07076719403266907), np.float64(1.638075590133667), np.float64(-1.186326026916504), np.float64(0.07782134413719177), np.float64(0.46678397059440613), np.float64(0.593088686466217), np.float64(-1.4323407411575317), np.float64(0.9997730851173401), np.float64(0.6238863468170166), np.float64(0.5513179302215576), np.float64(-0.848941445350647), np.float64(0.9994653463363647), np.float64(0.39380842447280884), np.float64(0.52937912940979), np.float64(-0.7239376902580261), np.float64(0.9996926784515381), np.float64(0.0707930251955986), np.float64(1.6382718086242676), np.float64(-1.1105808019638062), np.float64(0.07714884728193283), np.float64(0.0707930251955986), np.float64(1.6382718086242676), np.float64(-1.1105808019638062), np.float64(0.07714884728193283), np.float64(0.4711584746837616), np.float64(0.5938749313354492), np.float64(-1.4070172309875488), np.float64(0.9997828602790833), np.float64(0.6252191662788391), np.float64(0.5514355301856995), np.float64(-0.8302866220474243), np.float64(0.9994856715202332), np.float64(0.39382272958755493), np.float64(0.5299080014228821), np.float64(-0.6957554817199707), np.float64(0.9997062087059021), np.float64(0.0709216445684433), np.float64(1.6383689641952515), np.float64(-1.0879075527191162), np.float64(0.07654467970132828), np.float64(0.0709216445684433), np.float64(1.6383689641952515), np.float64(-1.0879075527191162), np.float64(0.07654467970132828), np.float64(0.48867395520210266), np.float64(0.5941900610923767), np.float64(-1.4881027936935425), np.float64(0.9997749328613281), np.float64(0.6283690333366394), np.float64(0.5514423847198486), np.float64(-0.8744237422943115), np.float64(0.9994621276855469), np.float64(0.39509889483451843), np.float64(0.5313823223114014), np.float64(-0.7776622772216797), np.float64(0.9996951222419739), np.float64(0.07017208635807037), np.float64(1.642913579940796), np.float64(-1.0901563167572021), np.float64(0.07614104449748993), np.float64(0.07017208635807037), np.float64(1.642913579940796), np.float64(-1.0901563167572021), np.float64(0.07614104449748993), np.float64(0.5095495581626892), np.float64(0.5947794318199158), np.float64(-1.5616816282272339), np.float64(0.999782145023346), np.float64(0.6355193853378296), np.float64(0.551464319229126), np.float64(-0.9144811034202576), np.float64(0.9994786977767944), np.float64(0.39766719937324524), np.float64(0.5335262417793274), np.float64(-0.8551820516586304), np.float64(0.9997050166130066), np.float64(0.0741419568657875), np.float64(1.6428554058074951), np.float64(-1.138523817062378), np.float64(0.0766148790717125), np.float64(0.0741419568657875), np.float64(1.6428554058074951), np.float64(-1.138523817062378), np.float64(0.0766148790717125), np.float64(0.525128185749054), np.float64(0.5953317880630493), np.float64(-1.5329660177230835), np.float64(0.9997739195823669), np.float64(0.640868604183197), np.float64(0.5509961843490601), np.float64(-0.9025875926017761), np.float64(0.9994468688964844), np.float64(0.40125131607055664), np.float64(0.5376361012458801), np.float64(-0.8459131717681885), np.float64(0.9996949434280396), np.float64(0.0796339139342308), np.float64(1.6465911865234375), np.float64(-1.1224615573883057), np.float64(0.0766376405954361), np.float64(0.0796339139342308), np.float64(1.6465911865234375), np.float64(-1.1224615573883057), np.float64(0.0766376405954361), np.float64(0.5433142781257629), np.float64(0.5958759784698486), np.float64(-1.6225652694702148), np.float64(0.9997552633285522), np.float64(0.6472147107124329), np.float64(0.5505074858665466), np.float64(-0.9496679902076721), np.float64(0.9993939399719238), np.float64(0.4042549133300781), np.float64(0.5422723293304443), np.float64(-0.9663233160972595), np.float64(0.9996729493141174), np.float64(0.08012717962265015), np.float64(1.6462510824203491), np.float64(-1.0423039197921753), np.float64(0.07533189654350281), np.float64(0.08012717962265015), np.float64(1.6462510824203491), np.float64(-1.0423039197921753), np.float64(0.07533189654350281), np.float64(0.5580642819404602), np.float64(0.5995600819587708), np.float64(-1.6554896831512451), np.float64(0.9997406601905823), np.float64(0.6553309559822083), np.float64(0.5505459308624268), np.float64(-0.9729268550872803), np.float64(0.9993460774421692), np.float64(0.4077370762825012), np.float64(0.5446202158927917), np.float64(-1.01404869556427), np.float64(0.9996584057807922), np.float64(0.08411398530006409), np.float64(1.64895498752594), np.float64(-1.0555578470230103), np.float64(0.07412958890199661), np.float64(0.08411398530006409), np.float64(1.64895498752594), np.float64(-1.0555578470230103), np.float64(0.07412958890199661), np.float64(0.5699834227561951), np.float64(0.6008844971656799), np.float64(-1.7373144626617432), np.float64(0.9997302293777466), np.float64(0.6626164317131042), np.float64(0.5512442588806152), np.float64(-1.0282920598983765), np.float64(0.9993157386779785), np.float64(0.4113391935825348), np.float64(0.5446767807006836), np.float64(-1.072187066078186), np.float64(0.9996528625488281), np.float64(0.086162269115448), np.float64(1.655051589012146), np.float64(-1.196651816368103), np.float64(0.07278723269701004), np.float64(0.086162269115448), np.float64(1.655051589012146), np.float64(-1.196651816368103), np.float64(0.07278723269701004), np.float64(0.5758821964263916), np.float64(0.6008694171905518), np.float64(-1.7113523483276367), np.float64(0.9997255206108093), np.float64(0.6710252165794373), np.float64(0.5514560341835022), np.float64(-1.0129554271697998), np.float64(0.9992954730987549), np.float64(0.4166015088558197), np.float64(0.5441927909851074), np.float64(-1.0721535682678223), np.float64(0.9996489882469177), np.float64(0.0960826724767685), np.float64(1.6538751125335693), np.float64(-1.1802130937576294), np.float64(0.07096187770366669), np.float64(0.0960826724767685), np.float64(1.6538751125335693), np.float64(-1.1802130937576294), np.float64(0.07096187770366669), np.float64(0.5777541995048523), np.float64(0.6010722517967224), np.float64(-1.7018013000488281), np.float64(0.9997265338897705), np.float64(0.6751822233200073), np.float64(0.551772952079773), np.float64(-1.0079997777938843), np.float64(0.9992806911468506), np.float64(0.4195602536201477), np.float64(0.5440515875816345), np.float64(-1.0681507587432861), np.float64(0.9996474981307983), np.float64(0.09995965659618378), np.float64(1.6536906957626343), np.float64(-1.1562680006027222), np.float64(0.07022518664598465), np.float64(0.09995965659618378), np.float64(1.6536906957626343), np.float64(-1.1562680006027222), np.float64(0.07022518664598465)]\n"
     ]
    }
   ],
   "source": [
    "class_name = \"CelingakCelinguk\"\n",
    "camera = cv2.VideoCapture(\"http://192.168.100.197:5000/video\")\n",
    "\n",
    "frames = []\n",
    "detected = []\n",
    "face_direction = []\n",
    "\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    print(\"Camera is ready. Press 'q' to quit.\")\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    start_time = time.time()\n",
    "    while camera.isOpened:\n",
    "        countdown_time = 3\n",
    "        \n",
    "        ret, frame = camera.read()\n",
    "        \n",
    "        if ret:\n",
    "\n",
    "            frame = cv2.resize(frame, (original_width, original_height))\n",
    "\n",
    "            if len(frames) < num_frames:\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "                \n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                nose = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE]\n",
    "                ear_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EAR]\n",
    "                ear_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EAR]\n",
    "                wrist_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "                wrist_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "                temporary_list = []\n",
    "                temporary_list.append(nose)\n",
    "                temporary_list.append(ear_l)\n",
    "                temporary_list.append(ear_r)\n",
    "                temporary_list.append(wrist_r)\n",
    "                temporary_list.append(wrist_l)\n",
    "                \n",
    "                face_direction.append(check_direction({\"nose\": nose.x, \"ear_r\": ear_r.x, \"ear_l\": ear_l.x}))\n",
    "                detected.append(temporary_list)\n",
    "                \n",
    "            else:\n",
    "                frames.pop(0)\n",
    "                face_direction.pop(0)\n",
    "                detected.pop(0)\n",
    "                frames.append(cv2.resize(frame, (small_width, small_height)))\n",
    "\n",
    "                frame_detected = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_detected.flags.writeable = False\n",
    "                results = holistic.process(frame_detected)\n",
    "                frame_detected.flags.writeable = True\n",
    "                frame_detected = cv2.cvtColor(frame_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                nose = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.NOSE]\n",
    "                ear_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_EAR]\n",
    "                ear_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.LEFT_EAR]\n",
    "                wrist_r = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "                wrist_l = results.pose_landmarks.landmark[mp.solutions.holistic.PoseLandmark.RIGHT_WRIST]\n",
    "                \n",
    "                temporary_list = []\n",
    "                temporary_list.append(nose)\n",
    "                temporary_list.append(ear_l)\n",
    "                temporary_list.append(ear_r)\n",
    "                temporary_list.append(wrist_r)\n",
    "                temporary_list.append(wrist_l)\n",
    "                \n",
    "                face_direction.append(check_direction({\"nose\": nose.x, \"ear_r\": ear_r.x, \"ear_l\": ear_l.x}))\n",
    "                detected.append(temporary_list)\n",
    "\n",
    "            if len(frames) >= 15:\n",
    "                stacked1_frames = np.vstack((frames[0], frames[1], frames[2]))\n",
    "                stacked2_frames = np.vstack((frames[3], frames[4], frames[5]))\n",
    "                stacked3_frames = np.vstack((frames[6], frames[7], frames[8]))\n",
    "                stacked4_frames = np.vstack((frames[9], frames[10], frames[11]))\n",
    "                stacked5_frames = np.vstack((frames[12], frames[13], frames[14]))\n",
    "\n",
    "                stacked1_frames = cv2.resize(stacked1_frames, (small_width, original_height))\n",
    "                stacked2_frames = cv2.resize(stacked2_frames, (small_width, original_height))\n",
    "                stacked3_frames = cv2.resize(stacked3_frames, (small_width, original_height))\n",
    "                stacked4_frames = cv2.resize(stacked4_frames, (small_width, original_height))\n",
    "                stacked5_frames = cv2.resize(stacked5_frames, (small_width, original_height))\n",
    "                \n",
    "                final_layout = np.hstack((frame, stacked1_frames, stacked2_frames, stacked3_frames, stacked4_frames, stacked5_frames))\n",
    "            else:\n",
    "                final_layout = frame\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            flat_detected = [landmark for sublist in detected for landmark in sublist]\n",
    "\n",
    "            landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "            landmark_list.landmark.extend(flat_detected)\n",
    "            \n",
    "            cv2.imshow(\"Camera Capture\", final_layout)\n",
    "\n",
    "            # Print the elapsed time in seconds since the start of the loop\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "            if elapsed <= 3:\n",
    "                print(f\"Elapsed time: {elapsed} seconds\")\n",
    "                    \n",
    "            else:\n",
    "                lv = landmark_list.landmark\n",
    "\n",
    "                counter = 0\n",
    "                featureper_frames = 0\n",
    "                dataset_row = []\n",
    "                \n",
    "                for lndmrk in lv:\n",
    "                    dataset_row.append(lndmrk.x)\n",
    "                    dataset_row.append(lndmrk.y)\n",
    "                    dataset_row.append(lndmrk.z)\n",
    "                    dataset_row.append(lndmrk.visibility)\n",
    "                    counter += 1\n",
    "\n",
    "                    if counter % 5 == 0:\n",
    "                        dataset_row.append(face_direction[featureper_frames])\n",
    "                        featureper_frames += 1 \n",
    "\n",
    "                dataset_row = list(np.array(dataset_row))\n",
    "                dataset_row.insert(0, class_name)\n",
    "\n",
    "                with open(file_csv, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(dataset_row)\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey (1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb20e62",
   "metadata": {},
   "source": [
    "# - NOTE -\n",
    "1. West, East detection where we see as additional of parameter when detecting suspicious activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633929fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/users/nawfal/documents/apps/collaborative project/cctv_motion_detection/pose_env/bin/python'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc473f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440347b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motion_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
